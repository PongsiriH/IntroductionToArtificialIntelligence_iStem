{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from robot_simulation import CrawlingRobotSimulator\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio\n",
    "import pygame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrawlingRobotEnvironment:\n",
    "    def __init__(self, goal_x=100, robot_friction=0.1):\n",
    "        self.eps = 0.01\n",
    "        self.sim = CrawlingRobotSimulator()\n",
    "        self.sim.init()\n",
    "        self.sim.chassis_shape.friction = robot_friction\n",
    "        self.possible_actions = [0, 1, 2, 3]\n",
    "        self.state_bins = [\n",
    "            np.linspace(self.sim.min_rightLeg_1b_angle, self.sim.max_rightLeg_1b_angle, 10),\n",
    "            np.linspace(self.sim.min_rightLeg_1a_angle, self.sim.max_rightLeg_1a_angle, 5),\n",
    "        ]\n",
    "        self.num_actions = len(self.possible_actions)\n",
    "        self.num_states = self.state_bins[0].shape + self.state_bins[1].shape\n",
    "        self.goal_x = goal_x\n",
    "        self.t_input = 100 # how much time passed after last input was taken.\n",
    "        \n",
    "    def reset(self):\n",
    "        self.sim.reset_bodies(self.sim.chassisXY)\n",
    "        _, ba1Angle, ac1Angle = self.sim.get_states()\n",
    "        return ba1Angle, ac1Angle\n",
    "    \n",
    "    def step(self, action, render=False):\n",
    "        reward = 0\n",
    "        done = False\n",
    "        x_old, _, _ = self.sim.get_states()\n",
    "        \n",
    "        # handle actions\n",
    "        for event in pygame.event.get():\n",
    "            if event.type == pygame.QUIT:\n",
    "                pygame.quit()\n",
    "        motor_ba1 = self.sim.motor_ba1Right\n",
    "        motor_ac1 = self.sim.motor_ac1Right\n",
    "        \n",
    "        if action == 0: # hand\n",
    "            new_angle = motor_ba1.angle() + np.deg2rad(20)\n",
    "            motor_ba1.set_target_angle(new_angle)\n",
    "            pass\n",
    "        elif action == 1: # hand\n",
    "            new_angle = motor_ba1.angle() - np.deg2rad(20)\n",
    "            motor_ba1.set_target_angle(new_angle)\n",
    "            pass\n",
    "        elif action == 2: # arm\n",
    "            new_angle = motor_ac1.angle() - np.deg2rad(10)\n",
    "            motor_ac1.set_target_angle(new_angle)\n",
    "        elif action == 3: # arm\n",
    "            new_angle = motor_ac1.angle() + np.deg2rad(10)\n",
    "            motor_ac1.set_target_angle(new_angle)\n",
    "        else:\n",
    "            motor_ba1.rate = 0\n",
    "            motor_ac1.rate = 0\n",
    "            \n",
    "        while True:\n",
    "            for motor in self.sim.motor_list:\n",
    "                motor.update()\n",
    "            self.sim.update_simulation()\n",
    "            if render:\n",
    "                self.render()\n",
    "            _, aaaaa, bbbbb = self.sim.get_states()\n",
    "            if abs(aaaaa - motor_ba1.target_angle) < self.eps and abs(bbbbb - motor_ac1.target_angle) < self.eps:\n",
    "                break\n",
    "\n",
    "        # reward.\n",
    "        x, ba1Angle, ac1Angle = self.sim.get_states()\n",
    "        observation = (ba1Angle, ac1Angle)\n",
    "        \n",
    "        reward += (x-x_old)\n",
    "\n",
    "        if x < -20:\n",
    "            done = True\n",
    "        elif x > self.goal_x:\n",
    "            done = True\n",
    "        return observation, reward, done\n",
    "    \n",
    "    def render(self):\n",
    "        self.sim.draw()\n",
    "\n",
    "class QAgent:\n",
    "    def __init__(\n",
    "        self, \n",
    "        env: CrawlingRobotEnvironment,\n",
    "        num_episodes=500,\n",
    "        learning_rate=0.1,\n",
    "        discount_factor=0.999,\n",
    "        epsilon=1,\n",
    "        min_epsilon = 0.1,\n",
    "        epsilon_decay=0.9995\n",
    "        ):\n",
    "        self.num_episodes = num_episodes\n",
    "        self.learning_rate = learning_rate\n",
    "        self.discount_factor =discount_factor\n",
    "        self.epsilon = epsilon\n",
    "        self.min_epsilon = min_epsilon\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "        self.possible_actions = env.possible_actions\n",
    "        self.state_bins = env.state_bins\n",
    "        # initialze Qtable as all zeros.\n",
    "        self.Qtable = np.zeros(env.num_states + (env.num_actions, ))\n",
    "    \n",
    "    def choose_action(self, state, greedy=False):\n",
    "        if np.random.rand() < self.epsilon and not greedy:\n",
    "            action = np.random.choice(self.possible_actions)\n",
    "        else:\n",
    "            state_index = self.discretize_state(state)\n",
    "            action = self.possible_actions[np.argmax(self.Qtable[state_index])]\n",
    "        return action\n",
    "\n",
    "    def update_q_value(self, state, action, reward, next_state):\n",
    "        state_index = self.discretize_state(state)\n",
    "        next_state_index = self.discretize_state(next_state)\n",
    "        action_index = self.possible_actions.index(action)\n",
    "        future_reward = np.max(self.Qtable[next_state_index])\n",
    "        current_q = self.Qtable[state_index][action_index]\n",
    "        self.Qtable[state_index][action_index] = current_q + self.learning_rate * (reward + self.discount_factor * future_reward - current_q)\n",
    "        \n",
    "    def discretize_state(self, state, hysteresis_margin=0.05):\n",
    "        \"\"\"Discretize state with a hysteresis margin to stabilize transitions.\"\"\"\n",
    "        arm_value = state[0]\n",
    "        hand_value = state[1]\n",
    "        arm_idx = np.digitize(arm_value, [x - hysteresis_margin for x in self.state_bins[0]]) - 1\n",
    "        hand_idx = np.digitize(hand_value, [x - hysteresis_margin for x in self.state_bins[1]]) - 1\n",
    "        return arm_idx, hand_idx\n",
    "\n",
    "    def decay_epsilon(self):\n",
    "        self.epsilon = max(self.min_epsilon, self.epsilon * self.epsilon_decay)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(fric):\n",
    "    pygame.font.init()\n",
    "    my_font = pygame.font.SysFont('Comic Sans MS', 20)\n",
    "    env = CrawlingRobotEnvironment(goal_x=200, robot_friction=fric)\n",
    "    agent = QAgent(env, num_episodes=50, learning_rate=0.1, discount_factor=0.99999, epsilon_decay=0.95)\n",
    "    rewards = []\n",
    "    try:\n",
    "        for episode in range(1,agent.num_episodes+1):\n",
    "            state = env.reset()\n",
    "            done = False\n",
    "            cumulative_reward = 0\n",
    "            while not done:\n",
    "                action = agent.choose_action(state)            \n",
    "                new_state, reward, done = env.step(action, render=False)\n",
    "                agent.update_q_value(state, action, reward, new_state)\n",
    "                state = new_state\n",
    "                cumulative_reward += reward\n",
    "                \n",
    "            agent.decay_epsilon()\n",
    "\n",
    "            rewards.append(cumulative_reward)\n",
    "            print(f'{episode}... eps {agent.epsilon:.2f}, reward {cumulative_reward}')\n",
    "            if episode % 100 == 0:\n",
    "                print(episode, cumulative_reward, agent.epsilon)\n",
    "    finally:\n",
    "        pygame.quit()\n",
    "    return agent\n",
    "\n",
    "def record(agent, fric, max_steps=1000):\n",
    "    frames = []\n",
    "    env = CrawlingRobotEnvironment(goal_x=500, robot_friction=fric)\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    while not done:\n",
    "        if len(frames) > max_steps:\n",
    "            break\n",
    "        action = agent.choose_action(state, greedy=True)\n",
    "        new_state, reward, done = env.step(action, render=True)\n",
    "        state = new_state\n",
    "        print('frame ', len(frames), agent.discretize_state(state))\n",
    "\n",
    "        # Capture the current frame\n",
    "        frame_shape = (env.sim.display_size[1], env.sim.display_size[0], 3)\n",
    "        raw_data = pygame.image.tostring(env.sim.screen, \"RGB\")\n",
    "        img = np.frombuffer(raw_data, dtype=np.uint8)\n",
    "        img = img.reshape(frame_shape)\n",
    "        frames.append(img)\n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists('animate'):\n",
    "    os.mkdir('animate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting simulation for: animate/crawlingRobot_fric0.7_1.mp4 ...........\n",
      "\n",
      "chassis position\n",
      "Vec2d(20.0, 120.0)\n"
     ]
    }
   ],
   "source": [
    "robot_frictions = [0.7, 0.05]\n",
    "# robot_frictions = [0.7]\n",
    "for fric in robot_frictions:\n",
    "    for i in range(1, 1+1):\n",
    "        file_name = f'animate/crawlingRobot_fric{fric}_{i}.mp4'\n",
    "        print(f'\\nStarting simulation for: {file_name} ...........\\n')\n",
    "        agent = train(fric)\n",
    "        try: \n",
    "            frames = record(agent, fric)\n",
    "        finally:\n",
    "            imageio.mimwrite(file_name, frames, fps=16)\n",
    "            pygame.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x19f177c1a20>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(agent.Qtable.max(axis=2), )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tflab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
