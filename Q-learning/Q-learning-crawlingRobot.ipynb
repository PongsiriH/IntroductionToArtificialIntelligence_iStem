{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio\n",
    "import pygame\n",
    "from robot_simulation import CrawlingRobotSimulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrawlingRobotEnvironment:\n",
    "    def __init__(self, goal_x=100, robot_friction=0.1):\n",
    "        self.eps = 0.01\n",
    "        self.sim = CrawlingRobotSimulator()\n",
    "        self.sim.init()\n",
    "        self.sim.body_shape.friction = robot_friction\n",
    "        self.possible_actions = [0, 1, 2, 3]\n",
    "        self.state_bins = [\n",
    "            np.linspace(self.sim.min_hand_angle, self.sim.max_hand_angle, 10),\n",
    "            np.linspace(self.sim.min_arm_angle, self.sim.max_arm_angle, 10),\n",
    "        ]\n",
    "        self.num_actions = len(self.possible_actions)\n",
    "        self.num_states = self.state_bins[0].shape + self.state_bins[1].shape\n",
    "        self.goal_x = goal_x\n",
    "        self.t_input = 100 # how much time passed after last input was taken.\n",
    "        \n",
    "    def reset(self):\n",
    "        self.sim.reset_bodies(self.sim.bodyXY)\n",
    "        _, handAngle, armAngle = self.sim.get_states()\n",
    "        return handAngle, armAngle\n",
    "    \n",
    "    def step(self, action, render=False):\n",
    "        reward = 0\n",
    "        done = False\n",
    "        x_old, _, _ = self.sim.get_states()\n",
    "        \n",
    "        # handle actions\n",
    "        for event in pygame.event.get():\n",
    "            if event.type == pygame.QUIT:\n",
    "                pygame.quit()\n",
    "        motor_hand = self.sim.motor_hand\n",
    "        motor_arm = self.sim.motor_arm\n",
    "        \n",
    "        if action == 0: # hand\n",
    "            new_angle = motor_hand.angle() + np.deg2rad(20)\n",
    "            motor_hand.set_target_angle(new_angle)\n",
    "            pass\n",
    "        elif action == 1: # hand\n",
    "            new_angle = motor_hand.angle() - np.deg2rad(20)\n",
    "            motor_hand.set_target_angle(new_angle)\n",
    "            pass\n",
    "        elif action == 2: # arm\n",
    "            new_angle = motor_arm.angle() - np.deg2rad(10)\n",
    "            motor_arm.set_target_angle(new_angle)\n",
    "        elif action == 3: # arm\n",
    "            new_angle = motor_arm.angle() + np.deg2rad(10)\n",
    "            motor_arm.set_target_angle(new_angle)\n",
    "        else:\n",
    "            motor_hand.rate = 0\n",
    "            motor_arm.rate = 0\n",
    "            \n",
    "        while True:\n",
    "            for motor in self.sim.motor_list:\n",
    "                motor.update()\n",
    "            self.sim.update_simulation()\n",
    "            if render:\n",
    "                self.render()\n",
    "            _, handAngle, armAngle = self.sim.get_states()\n",
    "            if abs(handAngle - motor_hand.target_angle) < self.eps and abs(armAngle - motor_arm.target_angle) < self.eps:\n",
    "                break\n",
    "\n",
    "        # reward.\n",
    "        x, handAngle, armAngle = self.sim.get_states()\n",
    "        observation = (handAngle, armAngle)\n",
    "        \n",
    "        reward += (x-x_old)\n",
    "\n",
    "        if x < -20:\n",
    "            done = True\n",
    "        elif x > self.goal_x:\n",
    "            done = True\n",
    "        return observation, reward, done\n",
    "    \n",
    "    def render(self):\n",
    "        self.sim.draw()\n",
    "\n",
    "class QAgent:\n",
    "    def __init__(\n",
    "        self, \n",
    "        env: CrawlingRobotEnvironment,\n",
    "        num_episodes=500,\n",
    "        learning_rate=0.1,\n",
    "        discount_factor=0.999,\n",
    "        epsilon=1,\n",
    "        min_epsilon = 0.1,\n",
    "        epsilon_decay=0.9995\n",
    "        ):\n",
    "        self.num_episodes = num_episodes\n",
    "        self.learning_rate = learning_rate\n",
    "        self.discount_factor =discount_factor\n",
    "        self.epsilon = epsilon\n",
    "        self.min_epsilon = min_epsilon\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "        self.possible_actions = env.possible_actions\n",
    "        self.state_bins = env.state_bins\n",
    "        # initialze Qtable as all zeros.\n",
    "        self.Qtable = np.zeros(env.num_states + (env.num_actions, ))\n",
    "    \n",
    "    def choose_action(self, state, greedy=False):\n",
    "        if np.random.rand() < self.epsilon and not greedy:\n",
    "            action = np.random.choice(self.possible_actions)\n",
    "        else:\n",
    "            state_index = self.discretize_state(state)\n",
    "            action = self.possible_actions[np.argmax(self.Qtable[state_index])]\n",
    "        return action\n",
    "\n",
    "    def update_q_value(self, state, action, reward, next_state):\n",
    "        state_index = self.discretize_state(state)\n",
    "        next_state_index = self.discretize_state(next_state)\n",
    "        action_index = self.possible_actions.index(action)\n",
    "        future_reward = np.max(self.Qtable[next_state_index])\n",
    "        current_q = self.Qtable[state_index][action_index]\n",
    "        self.Qtable[state_index][action_index] = current_q + self.learning_rate * (reward + self.discount_factor * future_reward - current_q)\n",
    "        \n",
    "    def discretize_state(self, state, hysteresis_margin=0.05):\n",
    "        \"\"\"Discretize state with a hysteresis margin to stabilize transitions.\"\"\"\n",
    "        arm_value = state[0]\n",
    "        hand_value = state[1]\n",
    "        arm_idx = np.digitize(arm_value, [x - hysteresis_margin for x in self.state_bins[0]]) - 1\n",
    "        hand_idx = np.digitize(hand_value, [x - hysteresis_margin for x in self.state_bins[1]]) - 1\n",
    "        return arm_idx, hand_idx\n",
    "\n",
    "    def decay_epsilon(self):\n",
    "        self.epsilon = max(self.min_epsilon, self.epsilon * self.epsilon_decay)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(fric):\n",
    "    pygame.font.init()\n",
    "    my_font = pygame.font.SysFont('Comic Sans MS', 20)\n",
    "    env = CrawlingRobotEnvironment(goal_x=200, robot_friction=fric)\n",
    "    agent = QAgent(env, num_episodes=20, learning_rate=0.1, discount_factor=0.99, epsilon_decay=0.85)\n",
    "    rewards = []\n",
    "    try:\n",
    "        for episode in range(1,agent.num_episodes+1):\n",
    "            state = env.reset()\n",
    "            done = False\n",
    "            cumulative_reward = 0\n",
    "            while not done:\n",
    "                action = agent.choose_action(state)            \n",
    "                new_state, reward, done = env.step(action, render=False)\n",
    "                agent.update_q_value(state, action, reward, new_state)\n",
    "                state = new_state\n",
    "                cumulative_reward += reward\n",
    "                \n",
    "            agent.decay_epsilon()\n",
    "\n",
    "            rewards.append(cumulative_reward)\n",
    "            print(f'{episode}... eps {agent.epsilon:.2f}, reward {cumulative_reward}')\n",
    "            if episode % 100 == 0:\n",
    "                print(episode, cumulative_reward, agent.epsilon)\n",
    "    finally:\n",
    "        pygame.quit()\n",
    "    return agent\n",
    "\n",
    "def record(agent, fric, max_steps=1000):\n",
    "    frames = []\n",
    "    env = CrawlingRobotEnvironment(goal_x=400, robot_friction=fric)\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    while not done:\n",
    "        if len(frames) > max_steps:\n",
    "            break\n",
    "        action = agent.choose_action(state, greedy=True)\n",
    "        new_state, reward, done = env.step(action, render=True)\n",
    "        state = new_state\n",
    "        print('frame ', len(frames), agent.discretize_state(state))\n",
    "\n",
    "        # Capture the current frame\n",
    "        frame_shape = (env.sim.display_size[1], env.sim.display_size[0], 3)\n",
    "        raw_data = pygame.image.tostring(env.sim.screen, \"RGB\")\n",
    "        img = np.frombuffer(raw_data, dtype=np.uint8)\n",
    "        img = img.reshape(frame_shape)\n",
    "        frames.append(img)\n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists('animate'):\n",
    "    os.mkdir('animate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting simulation for: animate/crawlingRobot_fric0.05_2.mp4 ...........\n",
      "\n",
      "body position\n",
      "Vec2d(20.0, 120.0)\n",
      "1... eps 0.85, reward -40.16920692734185\n",
      "2... eps 0.72, reward -42.19366250043025\n",
      "3... eps 0.61, reward -41.1782779882804\n",
      "4... eps 0.52, reward -42.691204724830065\n",
      "5... eps 0.44, reward 184.13242912621178\n",
      "6... eps 0.38, reward 183.43121999652385\n",
      "7... eps 0.32, reward 181.7451170444731\n",
      "8... eps 0.27, reward 185.55110565217817\n",
      "9... eps 0.23, reward 180.98828339055518\n",
      "10... eps 0.20, reward 180.17065691475315\n",
      "11... eps 0.17, reward 180.61495162013347\n",
      "12... eps 0.14, reward 185.70352212566223\n",
      "13... eps 0.12, reward 185.1641164654724\n",
      "14... eps 0.10, reward 181.1782823745901\n",
      "15... eps 0.10, reward 181.11567796877335\n",
      "16... eps 0.10, reward 182.1250084436732\n",
      "17... eps 0.10, reward 184.46329854713892\n",
      "18... eps 0.10, reward 181.63805174830054\n",
      "19... eps 0.10, reward 183.519003858677\n",
      "20... eps 0.10, reward 184.74744344276462\n",
      "body position\n",
      "Vec2d(20.0, 120.0)\n",
      "frame  0 (9, 1)\n",
      "frame  1 (7, 1)\n",
      "frame  2 (6, 1)\n",
      "frame  3 (5, 1)\n",
      "frame  4 (4, 1)\n",
      "frame  5 (2, 1)\n",
      "frame  6 (1, 1)\n",
      "frame  7 (0, 1)\n",
      "frame  8 (0, 5)\n",
      "frame  9 (0, 9)\n",
      "frame  10 (1, 9)\n",
      "frame  11 (1, 5)\n",
      "frame  12 (1, 1)\n",
      "frame  13 (0, 1)\n",
      "frame  14 (0, 5)\n",
      "frame  15 (0, 9)\n",
      "frame  16 (1, 9)\n",
      "frame  17 (1, 5)\n",
      "frame  18 (1, 1)\n",
      "frame  19 (0, 1)\n",
      "frame  20 (0, 5)\n",
      "frame  21 (0, 9)\n",
      "frame  22 (1, 9)\n",
      "frame  23 (1, 5)\n",
      "frame  24 (1, 1)\n",
      "frame  25 (0, 1)\n",
      "frame  26 (0, 5)\n",
      "frame  27 (0, 9)\n",
      "frame  28 (1, 9)\n",
      "frame  29 (1, 5)\n",
      "frame  30 (1, 1)\n",
      "frame  31 (0, 1)\n",
      "frame  32 (0, 5)\n",
      "frame  33 (0, 9)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'frames' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 9\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m: \n\u001b[1;32m----> 9\u001b[0m     frames \u001b[38;5;241m=\u001b[39m \u001b[43mrecord\u001b[49m\u001b[43m(\u001b[49m\u001b[43magent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfric\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "Cell \u001b[1;32mIn[13], line 38\u001b[0m, in \u001b[0;36mrecord\u001b[1;34m(agent, fric, max_steps)\u001b[0m\n\u001b[0;32m     37\u001b[0m action \u001b[38;5;241m=\u001b[39m agent\u001b[38;5;241m.\u001b[39mchoose_action(state, greedy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 38\u001b[0m new_state, reward, done \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrender\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m state \u001b[38;5;241m=\u001b[39m new_state\n",
      "Cell \u001b[1;32mIn[12], line 57\u001b[0m, in \u001b[0;36mCrawlingRobotEnvironment.step\u001b[1;34m(self, action, render)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m render:\n\u001b[1;32m---> 57\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     58\u001b[0m _, handAngle, armAngle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msim\u001b[38;5;241m.\u001b[39mget_states()\n",
      "Cell \u001b[1;32mIn[12], line 75\u001b[0m, in \u001b[0;36mCrawlingRobotEnvironment.render\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrender\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m---> 75\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\pongs\\Downloads\\IntroductionToArtificialIntelligence_iStem\\Q-learning\\robot_simulation.py:110\u001b[0m, in \u001b[0;36mCrawlingRobotSimulator.draw\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdraw\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 110\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscreen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfill\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTHECOLORS\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwhite\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m### Clear the screen\u001b[39;00m\n\u001b[0;32m    111\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspace\u001b[38;5;241m.\u001b[39mdebug_draw(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdraw_options)  \u001b[38;5;66;03m### Draw space\u001b[39;00m\n",
      "\u001b[1;31merror\u001b[0m: display Surface quit",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m     frames \u001b[38;5;241m=\u001b[39m record(agent, fric)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m---> 11\u001b[0m     imageio\u001b[38;5;241m.\u001b[39mmimwrite(file_name, \u001b[43mframes\u001b[49m, fps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m)\n\u001b[0;32m     12\u001b[0m     pygame\u001b[38;5;241m.\u001b[39mquit()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'frames' is not defined"
     ]
    }
   ],
   "source": [
    "robot_frictions = [0.05, 0.5]\n",
    "# robot_frictions = [0.7]\n",
    "for fric in robot_frictions:\n",
    "    for i in range(2, 2+1):\n",
    "        file_name = f'animate/crawlingRobot_fric{fric}_{i}.mp4'\n",
    "        print(f'\\nStarting simulation for: {file_name} ...........\\n')\n",
    "        agent = train(fric)\n",
    "        try: \n",
    "            frames = record(agent, fric)\n",
    "        finally:\n",
    "            imageio.mimwrite(file_name, frames, fps=16)\n",
    "            pygame.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2820e620eb0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(agent.Qtable.max(axis=2), )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tflab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
